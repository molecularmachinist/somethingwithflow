{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.manifold import MDS, Isomap\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from scipy.special import kl_div\n",
    "import MDAnalysis as mda\n",
    "import sys\n",
    "import itertools\n",
    "from scipy.special import rel_entr\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "from scipy.spatial.distance import pdist, cdist\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import copy\n",
    "import skorch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selection = \"name CA\"\n",
    "data_dict = {}\n",
    "\n",
    "for system in glob.glob(\"../binding_spots_project/gpcr_sampling/b2ar/b2ar_centered_aligned/*\"):\n",
    "    name = system.split(\"/\")[-1]\n",
    "    cosmos = mda.Universe(glob.glob(f\"{system}/*gro\")[0], glob.glob(f\"{system}/*xtc\"))\n",
    "    size = cosmos.select_atoms(selection).positions.flatten()\n",
    "    pos = np.zeros(size.reshape(1, size.shape[0]).shape)\n",
    "    for ts in cosmos.trajectory:\n",
    "        pos = np.concatenate((pos, cosmos.select_atoms(selection).positions.reshape(1, pos.shape[1])))\n",
    "    pos = pos[~np.all(pos == 0, axis=1)]\n",
    "    data_dict[name] = pos\n",
    "    \n",
    "with open('data_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(data_dict, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_dict.pkl', 'rb') as handle:\n",
    "    data_dict = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system1, system2 = \"popc\", \"chol-site-3\"\n",
    "\n",
    "X = np.concatenate([v for k, v in data_dict.items() if k == system1 or k == system2])\n",
    "Y = np.concatenate([[-1 for i in range(data_dict[system1].shape[0])], [1 for i in range(data_dict[system2].shape[0])]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device.\n"
     ]
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_comps_dim_reduc = [i for i in range(2, 7)] if X.shape[1] > 5 else [i for i in range(2, X.shape[1])]\n",
    "n_comps_cluster = [i for i in range(2, 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "default_steps = {\n",
    "    \"dim_reducer\": {\n",
    "        PCA(): {\n",
    "            \"n_components\": n_comps_dim_reduc\n",
    "        }\n",
    "    },\n",
    "    \"classifier\": {\n",
    "        GaussianMixture(): {\n",
    "            \"n_components\": n_comps_cluster,\n",
    "            \"covariance_type\": [\"full\", \"spherical\", \"diag\", \"tied\"]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipelines(step_grid, X):\n",
    "    \n",
    "    reducers = step_grid[\"dim_reducer\"]\n",
    "    classifiers = step_grid[\"classifier\"]\n",
    "    combinations = list(itertools.product(reducers.keys(), classifiers.keys()))\n",
    "    pipelines = []\n",
    "    \n",
    "    for comb in combinations:\n",
    "        print(f\"fitting combination: {comb}\")\n",
    "        grid = {}\n",
    "        for param, values in step_grid[\"dim_reducer\"][comb[0]].items():\n",
    "            key = f\"dim_reducer__{param}\"\n",
    "            grid[key] = values\n",
    "        for param, values in step_grid[\"classifier\"][comb[1]].items():\n",
    "            key = f\"classifier__{param}\"\n",
    "            grid[key] = values\n",
    "        print(f\"with params {grid}\")\n",
    "        pipe = Pipeline(steps=[(\"dim_reducer\", comb[0]), (\"classifier\", comb[1])])\n",
    "        cv = GridSearchCV(pipe, param_grid=grid).fit(X)\n",
    "        pipelines.append(cv.best_estimator_)\n",
    "\n",
    "    return pipelines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def caluclate_KL(pipeline, X, Y):\n",
    "    \n",
    "    preds = pipeline.predict(X)\n",
    "    cluster_populations = []\n",
    "    for system in set(Y.flatten()):\n",
    "        system_preds = preds[np.where(Y == system)[0]]\n",
    "        populations = [system_preds[np.where(system_preds == i)].shape[0] / system_preds.shape[0] for i in set(preds)]\n",
    "        cluster_populations.append(populations)\n",
    "        \n",
    "    return sum(rel_entr(cluster_populations[0], cluster_populations[1])) # only two systems atm\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def flow(X, Y, step_grid):\n",
    "    \n",
    "    best_KL = 0\n",
    "    \n",
    "    pipelines = build_pipelines(step_grid=step_grid, X=X)\n",
    "    best_pipe = pipelines[0]\n",
    "    for pipe in pipelines:\n",
    "        KL = caluclate_KL(pipe, X, Y)\n",
    "        if KL > best_KL:\n",
    "            best_KL = KL\n",
    "            best_pipe = pipe\n",
    "    \n",
    "    return best_pipe, best_KL    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature selection\n",
    "    \n",
    "random seeds\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('sf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "9367d5d3b3259b4d4bf01b62cc0f0e1ca449aad14498d84cee5292445dca8140"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
