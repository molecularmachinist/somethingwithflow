{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import mpl_toolkits.mplot3d.axes3d as p3\n",
    "from sklearn.datasets import make_swiss_roll\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import pickle as pkl\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import MDAnalysis as mda\n",
    "import itertools\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def construct_encoder(input_dim, encoding_dim, dimensions_list, activation):\n",
    "    \n",
    "    encoder_layers = [nn.Linear(input_dim, dimensions_list[0]), activation]\n",
    "    decoder_layers = [nn.Linear(encoding_dim, dimensions_list[-1]), activation]\n",
    "\n",
    "    for i in range(len(dimensions_list) - 1):\n",
    "        encoder_layers.append(nn.Linear(dimensions_list[i], dimensions_list[i+1]))\n",
    "        encoder_layers.append(activation)\n",
    "        decoder_layers.append(nn.Linear(dimensions_list[::-1][i], dimensions_list[::-1][i+1]))\n",
    "        decoder_layers.append(activation)\n",
    "        \n",
    "    encoder_layers.append(nn.Linear(dimensions_list[-1], encoding_dim))\n",
    "    decoder_layers.append(nn.Linear(dimensions_list[0], input_dim))\n",
    "\n",
    "    encoder = nn.Sequential(*encoder_layers)\n",
    "    decoder = nn.Sequential(*decoder_layers)\n",
    "    \n",
    "    class Autoencoder(nn.Module):\n",
    "\n",
    "        def __init__(self, encoder, decoder):\n",
    "            super(Autoencoder, self).__init__()\n",
    "            self.encode = encoder\n",
    "            self.decode = decoder\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.encode(x)\n",
    "            x = self.decode(x)\n",
    "            return x\n",
    "\n",
    "    return Autoencoder(encoder=encoder, decoder=decoder)\n",
    "\n",
    "\n",
    "A = construct_encoder(10, 3, [7, 6, 5], nn.ReLU())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "construct_encoder() missing 4 required positional arguments: 'input_dim', 'encoding_dim', 'dimensions_list', and 'activation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_445387/3770112314.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model = NeuralNetClassifier(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: construct_encoder() missing 4 required positional arguments: 'input_dim', 'encoding_dim', 'dimensions_list', and 'activation'"
     ]
    }
   ],
   "source": [
    "model = NeuralNetClassifier(\n",
    "    module = construct_encoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
      "  module=Autoencoder(\n",
      "    (encode): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=7, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=7, out_features=6, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=6, out_features=5, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=5, out_features=3, bias=True)\n",
      "    )\n",
      "    (decode): Sequential(\n",
      "      (0): Linear(in_features=3, out_features=5, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=5, out_features=6, bias=True)\n",
      "      (3): ReLU()\n",
      "      (4): Linear(in_features=6, out_features=7, bias=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=7, out_features=10, bias=True)\n",
      "    )\n",
      "  ),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(encoder, loss_function, optimizer, n_epochs, batch_size, X):\n",
    "    \n",
    "    encoder.train()\n",
    "    indices = [i for i in range(X.shape[0])]\n",
    "    \n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        \n",
    "        random.shuffle(indices)\n",
    "        batches = [i for i in range(0, len(indices), batch_size)]\n",
    "\n",
    "        for i in range(len(batches) - 1):\n",
    "            \n",
    "            batch_X = X[indices[batches[i]:batches[i+1]]]\n",
    "            optimizer.zero_grad()\n",
    "            output = encoder(batch_X)\n",
    "            loss = loss_function(output, batch_X)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"epoch {epoch} \\t Loss: {loss.item():.4g}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(np.load(\"drors_for_all.npy\"))\n",
    "ids = X[:,-1]\n",
    "X = X[:,[0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 \t Loss: 0.6083810329437256\n",
      "epoch 2 \t Loss: 0.550406277179718\n",
      "epoch 3 \t Loss: 0.4399120807647705\n",
      "epoch 4 \t Loss: 0.49019306898117065\n",
      "epoch 5 \t Loss: 0.41201677918434143\n",
      "epoch 6 \t Loss: 0.46115174889564514\n",
      "epoch 7 \t Loss: 0.3997623324394226\n",
      "epoch 8 \t Loss: 0.45789313316345215\n",
      "epoch 9 \t Loss: 0.4028245806694031\n",
      "epoch 10 \t Loss: 0.37134426832199097\n"
     ]
    }
   ],
   "source": [
    "AE = construct_encoder(X.shape[1], 2, [8], nn.ReLU())\n",
    "loss_fn = nn.L1Loss()\n",
    "optimizer = optim.Adam(AE.parameters(), lr=1e-3)\n",
    "\n",
    "train(AE, loss_fn, optimizer, 10, 32, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on test set: 0.4530966281890869\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    encoded = AE.encode(X)\n",
    "    decoded = AE.decode(encoded)\n",
    "    err = loss_fn(decoded, X).item()\n",
    "    print(f\"Error on test set: {err}\")\n",
    "    E = decoded - X\n",
    "    enc = encoded.cpu().detach().numpy()\n",
    "    dec = decoded.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def construct_params(X):\n",
    "    \n",
    "    next = 2**np.ceil(np.log(X.shape[1])/np.log(2))\n",
    "    to_try = [next/4, next/2, next, 2*next, 4*next]\n",
    "\n",
    "\n",
    "construct_params(np.zeros((1, 16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(pow(2,4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
