{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import align\n",
    "from MDAnalysis.analysis.distances import distance_array\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonality loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthoLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, type=\"mse\", reduction=\"mean\"):\n",
    "        \"\"\"\n",
    "        A loss function for making a latent space orthonormal. In this case orthonormality\n",
    "        means that given an input matrix X of shape(n, d) of n data points\n",
    "        of d-dimensions, (X.T @ X) / n will be a d-dimensional identity matrix. The divisor\n",
    "        of n makes sure that if batch size is changed, the orthonormality condition stays the same.\n",
    "        \n",
    "        The loss defined by \"type\" is calculated over the (d,d) shaped error matrix (X.T @ X) / n - eye(d).\n",
    "        \n",
    "        The batch size should be sufficiently large and decorrelated for this loss to work.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        type: one of (\"mse\", \"l1\", \"l2\"), default=\"mse\"\n",
    "            How the loss is calculated from the error matrix.\n",
    "            mse: mean squared error (squared l2 error)\n",
    "            l1:  mean absolute error\n",
    "            l2:  root mean squared error\n",
    "        reduction: one of (\"sum\", \"mean\"), default=\"mean\"\n",
    "            How different batch size affects the result. With \"mean\" the error magnitude should stay\n",
    "            the same independent of the batch size. With \"sum\" the error matrix above is multiplied\n",
    "            by batch size, so the error grows linearily with batch size.\n",
    "            NOTE! due to  the error being calculated for the whole batch at once, the sum-reduction\n",
    "            has a different meaning to most other loss functions. With the mse type the output scales\n",
    "            as squared to the batch size instead of linearily, since the reduction is applied before\n",
    "            squaring.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        types = {\"mse\": self._mse,\n",
    "                 \"l1\":  self._l1,\n",
    "                 \"l2\":  self._l2}\n",
    "        errors = {\"sum\":  self._sum_error,\n",
    "                  \"mean\": self._mean_error}\n",
    "\n",
    "        if type not in types:\n",
    "            raise ValueError(f\"Unrecognised loss type \\\"{type}\\\"\")\n",
    "        if reduction not in errors:\n",
    "            raise ValueError(f\"Unrecognised loss reduction \\\"{reduction}\\\"\")\n",
    "        self.type=type\n",
    "        self.reduction=reduction\n",
    "        self._calc_loss = types[type]\n",
    "        self._calc_err  = errors[reduction]\n",
    "    \n",
    "    def forward(self, X):\n",
    "        n = X.shape[0]\n",
    "        d = X.shape[1]\n",
    "        nc_var = X.T @ X\n",
    "        target = torch.eye(d, device=X.device)\n",
    "        error = self._calc_err(nc_var, target, n)\n",
    "        return self._calc_loss(error, d)\n",
    "    \n",
    "    def _mse(self, error, d):\n",
    "        return (error*error).mean()\n",
    "    \n",
    "    def _l2(self, error, d):\n",
    "        return self._mse(error,d).sqrt()\n",
    "    \n",
    "    def _l1(self, error, d):\n",
    "        return torch.abs(error).mean()\n",
    "    \n",
    "    def _mean_error(self, dp, tgt, n):\n",
    "        return dp/n - tgt\n",
    "        \n",
    "    def _sum_error(self, dp, tgt, n):\n",
    "        return dp - tgt*n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Autoencoder(BaseEstimator, TransformerMixin, nn.Module):\n",
    "\n",
    "    def __init__(self, in_shape=10, enc_shape=2, middle_shape=5, n_hidden=1, loss_fn=nn.L1Loss(), lr=1e-3, ortholoss=False, ortholoss_weight=.01, l2_reg=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr \n",
    "        self.n_hidden = n_hidden # number of hidden layers\n",
    "        self.in_shape = in_shape # input dimension\n",
    "        self.enc_shape = enc_shape # dimension of encoding\n",
    "        self.middle_shape = middle_shape # hidden layer dimensions\n",
    "        self.ortholoss = ortholoss\n",
    "        self.ortholoss_weight = ortholoss_weight\n",
    "        \n",
    "        if self.ortholoss:\n",
    "            self.ort = OrthoLoss()\n",
    "        \n",
    "        self.l2_reg = l2_reg\n",
    "        encoder_layers = [nn.Linear(self.in_shape, self.middle_shape), nn.ReLU(), nn.Dropout(0.2)] # initialize encoder layer list\n",
    "        decoder_layers = [nn.Linear(self.enc_shape, self.middle_shape), nn.ReLU(), nn.Dropout(0.2)] # initialize decoder layer list\n",
    "\n",
    "        for i in range(n_hidden - 1): # Add layers to encoder and decoder according to n_hidden and middle shape\n",
    "            encoder_layers.append(nn.Linear(self.middle_shape, self.middle_shape))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "            encoder_layers.append(nn.Dropout(0.2))\n",
    "            decoder_layers.append(nn.Linear(self.middle_shape, self.middle_shape))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "            decoder_layers.append(nn.Dropout(0.2))\n",
    "            \n",
    "        encoder_layers.append(nn.Linear(self.middle_shape, self.enc_shape)) # Final encoder layer\n",
    "        decoder_layers.append(nn.Linear(self.middle_shape, self.in_shape)) # Final decoder layer\n",
    "\n",
    "        self.encode = nn.Sequential(*encoder_layers) # Make encoder\n",
    "        self.decode = nn.Sequential(*decoder_layers) # Make decoder\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None, n_epochs=20, batch_size=32, verbose=False):\n",
    "        self.training = True # Enables e.g. dropouts to work\n",
    "        X = torch.Tensor(X)\n",
    "        indices = [i for i in range(X.shape[0])]\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr) # Adam only atm\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "        \n",
    "            random.shuffle(indices) # random shuffle to get random batches for each epoch\n",
    "            batches = [i for i in range(0, len(indices), batch_size)]\n",
    "\n",
    "            for i in range(len(batches) - 1):\n",
    "\n",
    "                batch_X = X[indices[batches[i]:batches[i+1]]]\n",
    "                self.optimizer.zero_grad() # reset optimizer\n",
    "                \n",
    "                encoded = self.encode(batch_X)\n",
    "                decoded = self.decode(encoded)\n",
    "                loss = self.loss_fn(decoded, batch_X)\n",
    "                if self.ortholoss:\n",
    "                    loss += self.ortholoss_weight*self.ort(encoded)\n",
    "                if self.l2_reg:\n",
    "                    l2 = torch.tensor(0.)\n",
    "                    for param in self.parameters():\n",
    "                        l2 += torch.norm(param, p=2)\n",
    "                    loss += .0001 * l2**2\n",
    "                    \n",
    "                loss.backward() # Backpropagate\n",
    "                self.optimizer.step() # Apply changes\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'epoch {epoch} \\t Loss: {loss.item():.4g}')\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        encoded = self.encode(torch.Tensor(X))\n",
    "        return encoded.cpu().detach().numpy()\n",
    "    \n",
    "    def inverse_transform(self, X, y=None):\n",
    "        decoded = self.decode(torch.Tensor(X))\n",
    "        return decoded.cpu().detach().numpy()\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        encoded = self.transform(X)\n",
    "        decoded = self.inverse_transform(encoded)\n",
    "        \n",
    "        return -self.loss_fn(torch.Tensor(X), torch.Tensor(decoded)) # Take negative to make GridSearchCV work properly\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device.\n"
     ]
    }
   ],
   "source": [
    "#device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = \"cpu\"  # GridSearchCV having issues with cuda\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, test_size):\n",
    "    \n",
    "    indices = [i for i in range(data.shape[0])]\n",
    "    scaler = StandardScaler().fit(data)\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    test_indices = indices[:int(test_size*len(indices))]\n",
    "    train_indices = indices[int(test_size*len(indices)):]\n",
    "    \n",
    "    test_X = data[test_indices,:]\n",
    "    train_X = data[train_indices,:]\n",
    "    test_X_scaled = scaler.transform(test_X)\n",
    "    train_X_scaled = scaler.transform(train_X)\n",
    "    \n",
    "    return train_X, train_X_scaled, test_X, test_X_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_space_l1(truth, decoding, scaler):\n",
    "    \n",
    "    decoding_orig_space = torch.Tensor(scaler.inverse_transform(decoding))\n",
    "    loss = nn.L1Loss()\n",
    "    return loss(torch.Tensor(truth), decoding_orig_space).item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X = np.load(\"./data/a2ar_common_ca_coordinates.npy\")\n",
    "AE = Autoencoder(in_shape=X.shape[1], enc_shape=2, middle_shape=1024, n_hidden=1, ortholoss=True, l2_reg=True)\n",
    "AE.fit(X, n_epochs=10, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of parameters for gridsearch\n",
    "\n",
    "param_grid = {\n",
    "    \"Autoencoder\":{\n",
    "        \"Autoencoder__middle_shape\": [512],\n",
    "        \"Autoencoder__enc_shape\": [2],\n",
    "        \"Autoencoder__n_hidden\": [1]\n",
    "    },\n",
    "    \"GMM\": {\n",
    "        \"n_components\": [4]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search parameters and return best model\n",
    "\n",
    "def best_pipeline(transformer, param_grid, X, cv=2):\n",
    "    \n",
    "    step_names = [\"Scaler\", \"Autoencoder\"]\n",
    "    params = {key: val for k, d in param_grid.items() for key, val in d.items() if k in step_names}\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (step_names[0], StandardScaler()),\n",
    "            (step_names[1], transformer),\n",
    "        ]   \n",
    "    )\n",
    "    \n",
    "    gridsearch = GridSearchCV(pipe, param_grid=params, verbose=3, cv=cv)\n",
    "    gridsearch.fit(X)\n",
    "    \n",
    "    return gridsearch.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input perturbation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def IPA(X, scaler, model):\n",
    "        \n",
    "    \n",
    "    index = np.arange(0, X.shape[1], 3)\n",
    "    effects = []\n",
    "    \n",
    "    for i in index:\n",
    "        shuffled = X.copy()\n",
    "        scaler.transform(shuffled)\n",
    "        shuffled = shuffle(shuffled)\n",
    "        rands = np.random.uniform(low=-2, high=2, size=(shuffled.shape[0],1))\n",
    "        rands = np.concatenate([rands, rands, rands], axis=1)\n",
    "        shuffled[:, i:i+3] = rands\n",
    "        encoded = model.transform(shuffled)\n",
    "        decoded = model.inverse_transform(encoded)\n",
    "        decoded = scaler.inverse_transform(decoded)\n",
    "        L1 = np.mean(np.abs(X - decoded))\n",
    "        effects += [L1, L1, L1]\n",
    "    \n",
    "    return effects\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('sf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9367d5d3b3259b4d4bf01b62cc0f0e1ca449aad14498d84cee5292445dca8140"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
