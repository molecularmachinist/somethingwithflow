{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDAnalysis as mda\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making coordinate data (common atoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b2ar_traj_path = \"/wrk/eurastof/binding_spots_project/gpcr_sampling/b2ar/b2ar_centered_aligned/\"\n",
    "b2ar_common_ndx = \"/wrk/eurastof/binding_spots_project/HFSP---Lipid-binding-states/calculations/b2ar_common.ndx\"\n",
    "\n",
    "with open(b2ar_common_ndx) as f:\n",
    "    lines = \"\".join(f.readlines())\n",
    "\n",
    "resids = \" \".join(re.findall(r\"\\d+\", lines)[1:])\n",
    "\n",
    "\n",
    "dirs = glob.glob(f\"{b2ar_traj_path}*\")\n",
    "coordinates = []\n",
    "\n",
    "for d in dirs:\n",
    "\n",
    "    gro = glob.glob(f\"{d}/*gro\")[0]\n",
    "    xtcs = glob.glob(f\"{d}/*xtc\")\n",
    "    cosmos = mda.Universe(gro, xtcs)\n",
    "    common_ca = cosmos.select_atoms(f\"bynum {resids}\")\n",
    "\n",
    "    for ts in cosmos.trajectory[0:-1:5]:\n",
    "        coords = common_ca.positions.flatten()\n",
    "        coordinates.append(coords.reshape(1, coords.shape[0]))\n",
    "\n",
    "X = np.concatenate(coordinates)\n",
    "np.save(\"./b2ar_common_ca_coordinates.npy\", X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Autoencoder(BaseEstimator, TransformerMixin, nn.Module):\n",
    "\n",
    "    def __init__(self, in_shape=10, enc_shape=2, middle_shape=5, n_hidden=1, loss_fn=nn.L1Loss(), lr=1e-3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "        self.lr = lr\n",
    "        self.n_hidden = n_hidden\n",
    "        self.in_shape = in_shape\n",
    "        self.enc_shape = enc_shape\n",
    "        self.middle_shape = middle_shape\n",
    "        \n",
    "        encoder_layers = [nn.Linear(self.in_shape, self.middle_shape), nn.ReLU(), nn.Dropout(0.2)]\n",
    "        decoder_layers = [nn.Linear(self.enc_shape, self.middle_shape), nn.ReLU(), nn.Dropout(0.2)]\n",
    "\n",
    "        for i in range(n_hidden - 1):\n",
    "            encoder_layers.append(nn.Linear(self.middle_shape, self.middle_shape))\n",
    "            encoder_layers.append(nn.ReLU())\n",
    "            encoder_layers.append(nn.Dropout(0.2))\n",
    "            decoder_layers.append(nn.Linear(self.middle_shape, self.middle_shape))\n",
    "            decoder_layers.append(nn.ReLU())\n",
    "            decoder_layers.append(nn.Dropout(0.2))\n",
    "            \n",
    "        encoder_layers.append(nn.Linear(self.middle_shape, self.enc_shape))\n",
    "        decoder_layers.append(nn.Linear(self.middle_shape, self.in_shape))\n",
    "        decoder_layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.encode = nn.Sequential(*encoder_layers)\n",
    "        self.decode = nn.Sequential(*decoder_layers)\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None, n_epochs=20, batch_size=32, verbose=False):\n",
    "\n",
    "        self.training = True\n",
    "        X = torch.Tensor(X)\n",
    "        indices = [i for i in range(X.shape[0])]\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "        \n",
    "            random.shuffle(indices)\n",
    "            batches = [i for i in range(0, len(indices), batch_size)]\n",
    "\n",
    "            for i in range(len(batches) - 1):\n",
    "                \n",
    "                batch_X = X[indices[batches[i]:batches[i+1]]]\n",
    "                self.optimizer.zero_grad()\n",
    "                \n",
    "                encoded = self.encode(batch_X)\n",
    "                decoded = self.decode(encoded)\n",
    "\n",
    "                loss = self.loss_fn(decoded, batch_X)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            if verbose:\n",
    "                print(f'epoch {epoch} \\t Loss: {loss.item():.4g}')\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        encoded = self.encode(torch.Tensor(X))\n",
    "        return encoded.detach().numpy()\n",
    "    \n",
    "\n",
    "    def inverse_transform(self, X, y=None):\n",
    "        decoded = self.decode(torch.Tensor(X))\n",
    "        return decoded.detach().numpy()\n",
    "    \n",
    "    def score(self, X, y=None):\n",
    "        encoded = self.transform(X)\n",
    "        decoded = self.inverse_transform(encoded)\n",
    "        return self.loss_fn(torch.Tensor(X), torch.Tensor(decoded))\n",
    "        \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7900, 786)\n"
     ]
    }
   ],
   "source": [
    "X = np.load(\"./b2ar_common_ca_coordinates.npy\")\n",
    "print(X.shape)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"Scaler\", StandardScaler()),\n",
    "        (\"Autoencoder\", Autoencoder(in_shape=X.shape[1], middle_shape=1024, enc_shape=2, n_hidden=2)),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5; 1/2] START Autoencoder__middle_shape=1024..............................\n",
      "epoch 0 \t Loss: 0.7655\n",
      "epoch 1 \t Loss: 0.7266\n",
      "epoch 2 \t Loss: 0.6884\n",
      "[CV 1/5; 1/2] END Autoencoder__middle_shape=1024;, score=0.881 total time=   6.6s\n",
      "[CV 2/5; 1/2] START Autoencoder__middle_shape=1024..............................\n",
      "epoch 0 \t Loss: 0.7473\n",
      "epoch 1 \t Loss: 0.6599\n",
      "epoch 2 \t Loss: 0.7474\n",
      "[CV 2/5; 1/2] END Autoencoder__middle_shape=1024;, score=0.690 total time=   6.5s\n",
      "[CV 3/5; 1/2] START Autoencoder__middle_shape=1024..............................\n",
      "epoch 0 \t Loss: 0.732\n",
      "epoch 1 \t Loss: 0.7131\n",
      "epoch 2 \t Loss: 0.8113\n",
      "[CV 3/5; 1/2] END Autoencoder__middle_shape=1024;, score=0.681 total time=   6.2s\n",
      "[CV 4/5; 1/2] START Autoencoder__middle_shape=1024..............................\n",
      "epoch 0 \t Loss: 0.6927\n",
      "epoch 1 \t Loss: 0.7394\n",
      "epoch 2 \t Loss: 0.7448\n",
      "[CV 4/5; 1/2] END Autoencoder__middle_shape=1024;, score=0.853 total time=   6.3s\n",
      "[CV 5/5; 1/2] START Autoencoder__middle_shape=1024..............................\n",
      "epoch 0 \t Loss: 0.7286\n",
      "epoch 1 \t Loss: 0.7131\n",
      "epoch 2 \t Loss: 0.7437\n",
      "[CV 5/5; 1/2] END Autoencoder__middle_shape=1024;, score=0.686 total time=   6.4s\n",
      "[CV 1/5; 2/2] START Autoencoder__middle_shape=2048..............................\n",
      "epoch 0 \t Loss: 0.7311\n",
      "epoch 1 \t Loss: 0.711\n",
      "epoch 2 \t Loss: 0.7139\n",
      "[CV 1/5; 2/2] END Autoencoder__middle_shape=2048;, score=0.875 total time=   6.2s\n",
      "[CV 2/5; 2/2] START Autoencoder__middle_shape=2048..............................\n",
      "epoch 0 \t Loss: 0.7461\n",
      "epoch 1 \t Loss: 0.7691\n",
      "epoch 2 \t Loss: 0.7142\n",
      "[CV 2/5; 2/2] END Autoencoder__middle_shape=2048;, score=0.706 total time=   6.5s\n",
      "[CV 3/5; 2/2] START Autoencoder__middle_shape=2048..............................\n",
      "epoch 0 \t Loss: 0.7216\n",
      "epoch 1 \t Loss: 0.7279\n",
      "epoch 2 \t Loss: 0.7306\n",
      "[CV 3/5; 2/2] END Autoencoder__middle_shape=2048;, score=0.673 total time=   6.0s\n",
      "[CV 4/5; 2/2] START Autoencoder__middle_shape=2048..............................\n",
      "epoch 0 \t Loss: 0.7219\n",
      "epoch 1 \t Loss: 0.7426\n",
      "epoch 2 \t Loss: 0.691\n",
      "[CV 4/5; 2/2] END Autoencoder__middle_shape=2048;, score=0.852 total time=   6.9s\n",
      "[CV 5/5; 2/2] START Autoencoder__middle_shape=2048..............................\n",
      "epoch 0 \t Loss: 0.7552\n",
      "epoch 1 \t Loss: 0.6919\n",
      "epoch 2 \t Loss: 0.7068\n",
      "[CV 5/5; 2/2] END Autoencoder__middle_shape=2048;, score=0.684 total time=   6.9s\n",
      "epoch 0 \t Loss: 0.7083\n",
      "epoch 1 \t Loss: 0.7951\n",
      "epoch 2 \t Loss: 0.6981\n"
     ]
    }
   ],
   "source": [
    "gcv = GridSearchCV(pipe, param_grid={\"Autoencoder__middle_shape\": [1024, 2048]}, verbose=10).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('Scaler', StandardScaler()),\n",
      "                ('Autoencoder',\n",
      "                 Autoencoder(enc_shape=2, in_shape=786, middle_shape=1024,\n",
      "                             n_hidden=2))])\n"
     ]
    }
   ],
   "source": [
    "print(gcv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"Autoencoder__middle_shape\": [512, 1024, 2048],\n",
    "    \"Autoencoder__enc_shape\": [2, 3, 4],\n",
    "    \"Autoencoder__n_hidden\": [1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(transformer, param_grid, X):\n",
    "    \n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"Scaler\", StandardScaler()),\n",
    "            (\"Autoencoder\", transformer),\n",
    "        ]   \n",
    "    )\n",
    "    \n",
    "    gridsearch = GridSearchCV(pipe, param_grid=param_grid, verbose=10)\n",
    "    gridsearch.fit(X)\n",
    "    \n",
    "    return gridsearch.best_estimator_\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "[CV 1/5; 1/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1\n",
      "[CV 1/5; 1/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1;, score=0.899 total time=   2.5s\n",
      "[CV 2/5; 1/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1\n",
      "[CV 2/5; 1/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1;, score=0.725 total time=   2.4s\n",
      "[CV 3/5; 1/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1\n",
      "[CV 3/5; 1/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1;, score=0.698 total time=   2.4s\n",
      "[CV 4/5; 1/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1\n",
      "[CV 4/5; 1/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1;, score=0.878 total time=   2.4s\n",
      "[CV 5/5; 1/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1\n",
      "[CV 5/5; 1/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=1;, score=0.711 total time=   2.3s\n",
      "[CV 1/5; 2/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=2\n",
      "[CV 1/5; 2/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=2;, score=0.902 total time=   2.3s\n",
      "[CV 2/5; 2/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=2\n",
      "[CV 2/5; 2/36] END Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=2;, score=0.732 total time=   2.3s\n",
      "[CV 3/5; 2/36] START Autoencoder__enc_shape=2, Autoencoder__middle_shape=512, Autoencoder__n_hidden=2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [148], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAutoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [145], line 11\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(transformer, param_grid, X)\u001b[0m\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(\n\u001b[1;32m      4\u001b[0m     steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m      5\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScaler\u001b[39m\u001b[38;5;124m\"\u001b[39m, StandardScaler()),\n\u001b[1;32m      6\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, transformer),\n\u001b[1;32m      7\u001b[0m     ]   \n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m gridsearch \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mgridsearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gridsearch\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;49;00m func, args, kwargs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:684\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39mif\u001b[39;00m y_train \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 684\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "Cell \u001b[0;32mIn [146], line 50\u001b[0m, in \u001b[0;36mAutoencoder.fit\u001b[0;34m(self, X, y, n_epochs, batch_size, verbose)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     49\u001b[0m encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(batch_X)\n\u001b[0;32m---> 50\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(decoded, batch_X)\n\u001b[1;32m     53\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/activation.py:295\u001b[0m, in \u001b[0;36mSigmoid.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 295\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49msigmoid(\u001b[39minput\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "best = pipeline(Autoencoder(in_shape=X.shape[1]), param_grid, X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
